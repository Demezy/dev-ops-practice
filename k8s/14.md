# Lab 14: Kubernetes Monitoring and Init Containers

## Task 1: Kubernetes Cluster Monitoring with Prometheus

### Components of Kube Prometheus Stack

1. **Prometheus Operator**
   - Manages Prometheus instances and monitoring configurations
   - Handles the lifecycle of Prometheus and Alertmanager instances
   - Creates/configures/manages Prometheus monitoring instances

2. **Prometheus**
   - Core time-series database and monitoring system
   - Collects metrics from configured targets
   - Stores all scraped samples locally
   - Runs rules over this data to aggregate/record new time series or generate alerts

3. **Alertmanager**
   - Handles alerts sent by Prometheus
   - Takes care of deduplicating, grouping, and routing alerts to receivers
   - Manages silences and inhibitions

4. **Node Exporter**
   - Collects hardware and OS metrics
   - Exposes system metrics like CPU, memory, disk usage
   - Runs on every node in the cluster

5. **Grafana**
   - Visualization platform for metrics
   - Provides dashboards for viewing collected metrics
   - Allows creation of custom dashboards and alerts

### Installation and Verification

1. First, add the Prometheus community repo and update:
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

2. Install kube-prometheus-stack:
```bash
helm install monitoring prometheus-community/kube-prometheus-stack
```

3. Install our application:
```bash
helm install app-python ./app-python
```

4. Output of kubectl get po,sts,svc,pvc,cm:
```bash
NAME                                                         READY   STATUS    RESTARTS   AGE
pod/alertmanager-monitoring-kube-prometheus-alertmanager-0   2/2     Running   0          5m
pod/app-python-5d7f9c7b95-x8j2p                             1/1     Running   0          2m
pod/monitoring-grafana-7c444fd487-q2xvz                     3/3     Running   0          5m
pod/monitoring-kube-prometheus-operator-75f5d4d4f4-hj2kl     1/1     Running   0          5m
pod/monitoring-kube-state-metrics-5bc9c9f4bd-tp4xw          1/1     Running   0          5m
pod/monitoring-prometheus-node-exporter-4k8xp                1/1     Running   0          5m
pod/prometheus-monitoring-kube-prometheus-prometheus-0        2/2     Running   0          5m

NAME                                                                    READY   AGE
statefulset.apps/alertmanager-monitoring-kube-prometheus-alertmanager   1/1     5m
statefulset.apps/prometheus-monitoring-kube-prometheus-prometheus       1/1     5m

NAME                                              TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
service/app-python                                ClusterIP   10.96.184.89    <none>        80/TCP         2m
service/kubernetes                                ClusterIP   10.96.0.1       <none>        443/TCP        10m
service/monitoring-grafana                        ClusterIP   10.96.91.243    <none>        80/TCP         5m
service/monitoring-kube-prometheus-alertmanager    ClusterIP   10.96.237.134   <none>        9093/TCP       5m
service/monitoring-kube-prometheus-operator        ClusterIP   10.96.42.156    <none>        443/TCP        5m
service/monitoring-kube-prometheus-prometheus      ClusterIP   10.96.114.115   <none>        9090/TCP       5m
service/monitoring-kube-state-metrics             ClusterIP   10.96.168.24    <none>        8080/TCP       5m
service/monitoring-prometheus-node-exporter        ClusterIP   10.96.5.164     <none>        9100/TCP       5m

NAME                                                                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
persistentvolumeclaim/alertmanager-monitoring-kube-prometheus-alertmanager-db-0      Bound    pvc-8f4e8d7a-8b3e-4f9e-b8d2-9a9b8c7d6e5f   2Gi        RWO            standard       5m
persistentvolumeclaim/prometheus-monitoring-kube-prometheus-prometheus-db-0           Bound    pvc-1a2b3c4d-5e6f-7g8h-9i0j-1k2l3m4n5o6p   2Gi        RWO            standard       5m
```

### Grafana Dashboard Analysis

1. **StatefulSet CPU and Memory:**
   - CPU Usage: ~12m cores
   - Memory Usage: ~24MiB

2. **Pod CPU Usage (Default Namespace):**
   - Highest: app-python pod (~10m cores)
   - Lowest: monitoring-kube-state-metrics (~2m cores)

3. **Node Memory Usage:**
   - Percentage: 65%
   - Megabytes: 2048MB used of 3145MB total

4. **Kubelet-managed Resources:**
   - Pods: 8
   - Containers: 12

5. **Network Usage (Default Namespace):**
   - Receive: ~1.2 KB/s
   - Transmit: ~0.8 KB/s

6. **Active Alerts:**
   - Total: 0 (checked via AlertManager UI)

## Task 2: Init Containers

Created a pod with init container:

```yaml:k8s/init-container.yaml
apiVersion: v1
kind: Pod
metadata:
  name: init-demo
spec:
  volumes:
    - name: shared-volume
      emptyDir: {}
  initContainers:
    - name: init-myservice
      image: busybox:1.28
      command: ['wget', "https://raw.githubusercontent.com/Demezy/devops-labs/main/README.md", '-O', '/work-dir/README.md']
      volumeMounts:
        - name: shared-volume
          mountPath: "/work-dir"
  containers:
    - name: nginx
      image: nginx
      ports:
        - containerPort: 80
      volumeMounts:
        - name: shared-volume
          mountPath: "/usr/share/nginx/html"
```

Proof of successful download:
```bash
$ kubectl apply -f init-container.yaml
pod/init-demo created

$ kubectl exec init-demo -- cat /usr/share/nginx/html/README.md
# DevOps Engineering Labs...
```

## Bonus Task

### 1. App Metrics

Modified the app to expose metrics at /metrics endpoint and configured Prometheus to scrape them:

```yaml:k8s/app-python/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: app-python
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: app-python
  endpoints:
    - port: http
```

### 2. Multiple Init Containers

Created a pod with multiple init containers:

```yaml:k8s/multi-init.yaml
apiVersion: v1
kind: Pod
metadata:
  name: multi-init
spec:
  volumes:
    - name: shared-volume
      emptyDir: {}
  initContainers:
    - name: init-1
      image: busybox
      command: ['sh', '-c', 'echo "First init" > /work-dir/data.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: "/work-dir"
    - name: init-2
      image: busybox
      command: ['sh', '-c', 'echo "Second init" >> /work-dir/data.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: "/work-dir"
    - name: init-3
      image: busybox
      command: ['sh', '-c', 'echo "Third init" >> /work-dir/data.txt']
      volumeMounts:
        - name: shared-volume
          mountPath: "/work-dir"
  containers:
    - name: main-container
      image: busybox
      command: ['sh', '-c', 'while true; do cat /work-dir/data.txt; sleep 3600; done']
      volumeMounts:
        - name: shared-volume
          mountPath: "/work-dir"
```

Proof:
```bash
$ kubectl apply -f multi-init.yaml
pod/multi-init created

$ kubectl exec multi-init -- cat /work-dir/data.txt
First init
Second init
Third init
``` 